# AI regulation, ethics, principles and data protection.

Regulations over the use of Artificial Intelligence (AI) vary greatly across countries we've investigated. All countries seem to acknowledge the ethical concerns that arise from the use of AI; however, this is not necessarily reflected in their regulations. On the other hand, the use of data, personal or otherwise, seems to have more regulatory scrutiny.  Since data is crucial for development of AI systems, data regulations impact the possible uses of AI.

Mexico is the weakest among all of them with no specific regulation over the use of AI and with no reason to expect this to change any time soon.  The AI strategy document prepared by NGOs, with the support from the Office of the Mexican President, does mention ethical concerns. However, there is no commitment from the current government to follow up on this document and the ethical regulations it proposes. In terms of data regulation, Mexico has The Federal Law on the Protection of Personal Data Held by Private Parties that was enacted in 2010 and is seen as outdated by many.

Regulatory scene in China, in general, is hard to dissect and it is no different for regulations over the use of AI. Ethical impacts of AI is clearly acknowledged as apparent by the white paper published in 2018 by China's Standards Administration. The country recently announced the "Personal Information Protection Law" which is expected to become effective in 2021 and regulate the processing of personal data and its misuse. On the other hand, the 2017 Cyber Security Law gives the Chinese government superior power in accessing citizens' data. In other words, personal data may have some protection against the 3rd parties but not the government.

Japan is arguably the country with the most emphasis on ethical concerns on AI. In fact it is the only one with very clear legislation addressing ethical concerns. "Social Principles of Human-Centric AI" is a clear commitment and desire to put humans at the front and center of the discussion with core principles of Dignity, Diversity and Inclusion, and Sustainability. While "AI Utilization Guidelines" (2019) lists the principles to follow for AI development and use, "Basic Act on the Advancement of Public" (2016), Private Sector Data Utilization and Cyber Physical Security Framework" and "Act on the Protection of Personal Information (APPI)" focus on use of data across private and public sector. Japan also follows "OECD Principles on AI" enacted in 2019.

The United Kingdom considers AI as a business opportunity and their driving force behind their strategy is fundamentally pragmatist. There is no regulation directly addressing the use of AI. That being said, there are institutions who are tasked with following the state of affairs, namely "AI Council", "Office for AI" and "Centre for Data Ethics and Innovation". The last one is tasked with identifying measures needed to make sure the development of AI is safe, ethical and innovative. Also, despite leaving the EU, the UK still, effectively, has GDPR as DPA 2018.

The European Union has arguably the most balanced approach to AI regulation. One one hand they try to leverage it as a tool for socio-economic development and on the other hand they aim to have an appropriate ethical and legal framework around it. The European Union is the only state that takes direct input from its citizens, as well as experts and stakeholders.
